{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7750ffae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "from timeit import default_timer as timer\n",
    "import time\n",
    "start = timer()\n",
    "import re\n",
    "url = \"https://krisha.kz/prodazha/kvartiry/almaty/?page=\"\n",
    "page = 1\n",
    "\n",
    "list_of_links = []\n",
    "print(\"Program started\")\n",
    "try:\n",
    "    while page <= 1000:\n",
    "        if page % 100 == 0:\n",
    "            print(\"Loading process: \", int(page / 100) * 10, \"%\",sep = \"\")\n",
    "        try:\n",
    "             \n",
    "            html_page = urllib.request.urlopen(url + str(page))\n",
    "            \n",
    "        except:\n",
    "            page += 1\n",
    "            break\n",
    "        soup = BeautifulSoup(html_page, \"html.parser\")\n",
    "        l = soup.findAll(\"div\", {\"class\": \"a-card__inc\"})\n",
    "        for l1 in l:\n",
    "            x = l1.find(\"a\", {\"class\": \"a-card__image\"}).get('href')\n",
    "            list_of_links.append(x)\n",
    "            print(x)\n",
    "        page += 1\n",
    "        \n",
    "        time.sleep(0.5)\n",
    "except KeyboardInterrupt:\n",
    "    print('Loop was Interrupted by keyboard')\n",
    "    \n",
    "pd.DataFrame(list_of_links,columns = ['link']).to_excel(r'C:/Users/danii/Jupyter Notebook Study/BIS Project/list_of_links.xlsx', index = False, header=True)    \n",
    "print(\"Loading already finished\")\n",
    "end = timer()\n",
    "print(\"Count of notes:\", len(list_of_links))    \n",
    "print(\"Time of execution:\", end - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8117b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "from timeit import default_timer as timer\n",
    "import time\n",
    "import re\n",
    "import errno\n",
    "start = timer()\n",
    "url = \"https://krisha.kz\"\n",
    "\n",
    "\n",
    "list_of_links = pd.read_excel('list_of_links.xlsx')\n",
    "\n",
    "Dataset = []\n",
    "size = len(list_of_links)\n",
    "print(\"Program started\")\n",
    "\n",
    "try:\n",
    "    # I parsed the web site by 1500 flats at one approach with some time intervals,\n",
    "    # on purpose to avoid the blocking of Http request.  \n",
    "    for i in range(0, 1500):\n",
    "        if i % 1926 == 0:\n",
    "            print(\"Loading process: \", int(i / 1926) * 10, \"%\",sep = \"\")\n",
    "        link = list_of_links['link'][i]\n",
    "        try:\n",
    "            html_page = urllib.request.urlopen(url + link)\n",
    "            soup = BeautifulSoup(html_page, \"html.parser\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "        \n",
    "        print(link)\n",
    "        \n",
    "            \n",
    "        \n",
    "        item = []\n",
    "        \n",
    "        #Operaion 0, scraping the count of rooms\n",
    "        l = soup.find(\"meta\", {\"name\": \"description\"})\n",
    "        x = int(re.findall('[0-9]+', l.get('content'))[0])\n",
    "        if x < 20:\n",
    "            item.append(x)\n",
    "        else:\n",
    "            l = soup.find(\"div\", {\"class\": \"gallery__main\"}).find(\"a\").find(\"picture\").find(\"img\").get('alt')\n",
    "            x = int(re.findall('[0-9]+', l)[0])\n",
    "            if x < 20:\n",
    "                item.append(x)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "\n",
    "        #Operaion 1, scraping the building type\n",
    "        l = soup.find(\"div\", {\"data-name\": \"flat.building\"})\n",
    "        if l is not None:\n",
    "            l2 = l.find(\"div\", {\"class\": \"offer__advert-short-info\"})\n",
    "            item.append(l2.text)\n",
    "        else:\n",
    "            item.append('?')\n",
    "        #Operaion 2, scraping the flats floors and the count of levels at building\n",
    "        l = soup.find(\"div\", {\"data-name\": \"flat.floor\"})\n",
    "        if l is not None:\n",
    "            l2 = l.find(\"div\", {\"class\": \"offer__advert-short-info\"})\n",
    "            l3 = re.findall('[0-9]+', l2.text)\n",
    "            if len(l3) == 2:\n",
    "                item.append(int(l3[0]))\n",
    "                item.append(int(l3[1]))\n",
    "            else:\n",
    "                item.append(0)\n",
    "                item.append(int(l3[0]))\n",
    "        else:\n",
    "            item.append(0)\n",
    "            item.append(0)\n",
    "        #Operaion 3, scraping the square of rooms\n",
    "        l = soup.find(\"div\", {\"data-name\": \"live.square\"})\n",
    "        l2 = l.find(\"div\", {\"class\": \"offer__advert-short-info\"})\n",
    "        l3 = re.findall('[0-9]+', l2.text)\n",
    "        item.append(int(l3[0]))\n",
    "        #Operaion 4, scraping the condition of flat\n",
    "        l = soup.find(\"div\", {\"data-name\": \"flat.renovation\"})\n",
    "        if l is not None:\n",
    "            l2 = l.find(\"div\", {\"class\": \"offer__advert-short-info\"})\n",
    "            item.append(l2.text)\n",
    "        else:\n",
    "            item.append('?')\n",
    "        #Operaion 5, scraping the year of building\n",
    "        l = soup.find(\"div\", {\"data-name\": \"house.year\"})\n",
    "        if l is not None:\n",
    "            l2 = l.find(\"div\", {\"class\": \"offer__advert-short-info\"})\n",
    "            item.append(int(l2.text))\n",
    "        else:\n",
    "            item.append('?')\n",
    "        #Operaion 6, scraping the balcony of flat\n",
    "        l = soup.find(\"dt\", {\"data-name\": \"flat.balcony\"})\n",
    "        if l is not None:\n",
    "\n",
    "            l2 = l.parent.find(\"dd\")\n",
    "            item.append(l2.text)\n",
    "        else:\n",
    "            item.append('?')\n",
    "\n",
    "        #Operaion 7, scraping the furniture of flat\n",
    "        l = soup.find(\"dt\", {\"data-name\": \"live.furniture\"})\n",
    "        if l is not None:\n",
    "\n",
    "            l2 = l.parent.find(\"dd\")\n",
    "            item.append(l2.text)\n",
    "        else:\n",
    "            item.append('?')\n",
    "        #Operaion 8, scraping the flooring of flat\n",
    "        l = soup.find(\"dt\", {\"data-name\": \"flat.flooring\"})\n",
    "        if l is not None:\n",
    "\n",
    "            l2 = l.parent.find(\"dd\")\n",
    "            item.append(l2.text)\n",
    "        else:\n",
    "            item.append('?')\n",
    "        #Operaion 9, scraping the dormitory of flat\n",
    "        l = soup.find(\"dt\", {\"data-name\": \"flat.priv_dorm\"})\n",
    "        if l is not None:\n",
    "\n",
    "            l2 = l.parent.find(\"dd\")\n",
    "            item.append(l2.text)\n",
    "        else:\n",
    "            item.append('?')\n",
    "        #Operaion 10, scraping the flat cost   \n",
    "        l = soup.find(\"meta\", {\"name\": \"og:title\"})\n",
    "        if l is not None:\n",
    "\n",
    "            item.append(int(re.findall('[0-9]+', l.get('content'))[-1]))\n",
    "        else:\n",
    "            item.append('?')\n",
    "        Dataset.append(item)\n",
    "\n",
    "        time.sleep(0.5)\n",
    "except KeyboardInterrupt:\n",
    "    print('Loop was Interrupted by keyboard')\n",
    "    pass\n",
    "# Dataset = pd.concat([pd.read_excel('dataset7500-9000.xlsx'), pd.DataFrame(Dataset, columns = ['Комнатность', 'Тип дома', 'Этаж', 'Этажность дома', 'Площадь, м²', 'Состояние', 'Год постройки', 'Балкон', 'Квартира меблирована', 'Пол', 'Бывшее общежитие', 'Стоимость'])], ignore_index=True)\n",
    "pd.DataFrame(Dataset, columns = ['Комнатность', 'Тип дома', 'Этаж', 'Этажность дома', 'Площадь, м²', 'Состояние', 'Год постройки', 'Балкон', 'Квартира меблирована', 'Пол', 'Бывшее общежитие', 'Стоимость']).to_excel(r'C:/Users/danii/Jupyter Notebook Study/Projects/Krisha Prediction Model/dataset.xlsx', index = False, header=True)\n",
    "# Dataset.to_excel('dataset7500-9000.xlsx', index = False, header=True)\n",
    "print(\"Loading already finished\")\n",
    "end = timer()\n",
    "print(\"Time of execution:\", end - start, \"seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
